# -*- coding: utf-8 -*-
"""feature_engineering.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aKmbkZBQjx5FES3fNGl-7rVXNum3IOq-
"""

import pandas as pd
import numpy as np

"""Deriving new features from the existing features"""

def calculate_engineered_features(transaction_data: dict):
    # Convert single transaction to DataFrame
    df = pd.DataFrame([transaction_data])
    # Convert TransactionDT to datetime if it's not already
    if isinstance(df['TransactionDT'].iloc[0], str):
        df['TransactionDT'] = pd.to_datetime(df['TransactionDT'])
    # Get historical transactions for the user
    historical_transactions = pd.read_sql(f"SELECT * FROM transactions WHERE User_ID = {transaction_data['User_ID']}",db.bind)
    if not historical_transactions.empty:
        historical_transactions['TransactionDT'] = pd.to_datetime(historical_transactions['TransactionDT'])
        df = pd.concat([historical_transactions, df]).reset_index(drop=True)
    # E features
    df['TransactionTimeSlot_E2'] = df['TransactionDT'].apply(lambda x: (
        0 if 10 <= x.hour < 14 else
        1 if 14 <= x.hour < 18 else
        2 if 18 <= x.hour < 22 else
        3 if x.hour >= 22 or x.hour < 2 else
        4 if 2 <= x.hour < 6 else 5   ))
    df['HourWithinSlot_E3'] = df['TransactionDT'].apply(lambda x: (
        x.hour - 10 if 10 <= x.hour < 14 else
        x.hour - 14 if 14 <= x.hour < 18 else
        x.hour - 18 if 18 <= x.hour < 22 else
        (x.hour - 22) if x.hour >= 22 else (x.hour + 2) if x.hour < 2 else
        x.hour - 2 if 2 <= x.hour < 6 else
        x.hour - 6 ))
    df['TransactionWeekday_E4'] = df['TransactionDT'].dt.weekday
    df['AvgTransactionInterval_E5'] = df.groupby('User_ID')['TransactionDT'].diff().dt.total_seconds() / 3600
    df['TransactionAmountVariance_E6'] = df.groupby('User_ID')['TransactionAmt'].transform(lambda x: x.std() if len(x) > 1 else 0)
    user_avg = df.groupby('User_ID')['TransactionAmt'].transform('mean')
    df['TransactionRatio_E7'] = df['TransactionAmt'] / user_avg
    df['MedianTransactionAmount_E8'] = df.groupby('User_ID')['TransactionAmt'].transform('median')
    window_24h = df.groupby('User_ID', group_keys=False).apply(lambda x: x[x['TransactionDT'] >= x['TransactionDT'].max() - pd.Timedelta(hours=24)]).reset_index(drop=True)
    df['AvgTransactionAmt24Hrs_E9'] = df['User_ID'].map(window_24h.groupby('User_ID')['TransactionAmt'].mean())
    df['TransactionVelocity_E10'] = window_24h.groupby('User_ID')['TransactionID'].transform('count')
    user_hour_freq = df.groupby(['User_ID', 'HourWithinSlot_E3']).size().reset_index(name='count')
    df['TimingAnomaly_E11'] = df.apply(lambda row: 1 if row['HourWithinSlot_E3'] not in user_hour_freq[user_hour_freq['User_ID'] == row['User_ID']]['HourWithinSlot_E3'].values else 0,axis=1    )
    user_region_freq = df.groupby(['User_ID', 'Order_Region']).size().reset_index(name='count')
    df['RegionAnomaly_E12'] = df.apply(lambda row: 1 if row['Order_Region'] not in user_region_freq[user_region_freq['User_ID'] == row['User_ID']]['Order_Region'].values else 0, axis=1    )
    df['HourlyTransactionCount_E13'] = df.groupby(['User_ID', 'HourWithinSlot_E3'])['TransactionID'].transform('count')
    df['DaysSinceLastTransac_D2'] = df.groupby('User_ID')['TransactionDT'].diff().dt.total_seconds() / 86400
    df['SameCardDaysDiff_D3'] = df.groupby('CardNumber')['TransactionDT'].diff().dt.total_seconds() / 86400
    df['SameAddressDaysDiff_D4'] = df.groupby(['User_Region', 'Order_Region'])['TransactionDT'].diff().dt.total_seconds() / 86400
    df['SameReceiverEmailDaysDiff_D10'] = df.groupby('Merchant_email')['TransactionDT'].diff().dt.total_seconds() / 86400
    df['SameDeviceTypeDaysDiff_D11'] = df.groupby('DeviceType')['TransactionDT'].diff().dt.total_seconds() / 86400
    # C series features
    df['TransactionCount_C1'] = df.groupby(['CardNumber', 'Order_Region'])['TransactionID'].transform('count')
    df['UniqueMerchants_C4'] = df.groupby('CardNumber')['Merchant'].transform('nunique')
    df['SameBRegionCount_C5'] = df.groupby(['User_ID', 'User_Region'])['TransactionID'].transform('count')
    df['SameDeviceCount_C6'] = df.groupby(['User_ID', 'DeviceType'])['TransactionID'].transform('count')
    df['UniqueBRegion_C11'] = df.groupby('User_ID')['User_Region'].transform('nunique')
    # M series features
    user_common_device = df.groupby('User_ID')['DeviceType'].agg(lambda x: x.mode().iloc[0] if not x.empty else None)
    df['DeviceMatching_M4'] = df.apply(lambda row: 1 if row['DeviceType'] == user_common_device.get(row['User_ID']) else 0,axis=1)
    df['PrevDevice'] = df.groupby('User_ID')['DeviceType'].shift(1)
    df['DeviceMismatch_M6'] = (df['DeviceType'] != df['PrevDevice']).astype(int)
    df['RegionMismatch_M8'] = (df['Order_Region'] != df['User_Region']).astype(int)
    df['TransactionConsistency_M9'] = df.apply(
        lambda row: sum([
            row['DeviceMatching_M4'],
            1 - row['DeviceMismatch_M6'],
            1 - row['RegionMismatch_M8'],
            1 if row['TransactionAmt'] <= row['MedianTransactionAmount_E8'] * 1.5 else 0]), axis=1    )
    # Return features for the current transaction
    result = {
        'TransactionTimeSlot_E2': int(df.iloc[-1]['TransactionTimeSlot_E2']),
        'HourWithinSlot_E3': int(df.iloc[-1]['HourWithinSlot_E3']),
        'TransactionWeekday_E4': int(df.iloc[-1]['TransactionWeekday_E4']),
        'AvgTransactionInterval_E5': float(df.iloc[-1]['AvgTransactionInterval_E5']) if not pd.isna(df.iloc[-1]['AvgTransactionInterval_E5']) else 0.0,
        'TransactionAmountVariance_E6': float(df.iloc[-1]['TransactionAmountVariance_E6']),
        'TransactionRatio_E7': float(df.iloc[-1]['TransactionRatio_E7']),
        'MedianTransactionAmount_E8': float(df.iloc[-1]['MedianTransactionAmount_E8']),
        'AvgTransactionAmt_24Hrs_E9': float(df.iloc[-1]['AvgTransactionAmt24Hrs_E9']) if not pd.isna(df.iloc[-1]['AvgTransactionAmt24Hrs_E9']) else 0.0,
        'TransactionVelocity_E10': int(df.iloc[-1]['TransactionVelocity_E10']),
        'TimingAnomaly_E11': int(df.iloc[-1]['TimingAnomaly_E11']),
        'RegionAnomaly_E12': int(df.iloc[-1]['RegionAnomaly_E12']),
        'HourlyTransactionCount_E13': int(df.iloc[-1]['HourlyTransactionCount_E13']),
        'DaysSinceLastTransac_D2': float(df.iloc[-1]['DaysSinceLastTransac_D2']) if not pd.isna(df.iloc[-1]['DaysSinceLastTransac_D2']) else 0.0,
        'SameCardDaysDiff_D3': float(df.iloc[-1]['SameCardDaysDiff_D3']) if not pd.isna(df.iloc[-1]['SameCardDaysDiff_D3']) else 0.0,
        'SameAddressDaysDiff_D4': float(df.iloc[-1]['SameAddressDaysDiff_D4']) if not pd.isna(df.iloc[-1]['SameAddressDaysDiff_D4']) else 0.0,
        'SameReceiverEmailDaysDiff_D10': float(df.iloc[-1]['SameReceiverEmailDaysDiff_D10']) if not pd.isna(df.iloc[-1]['SameReceiverEmailDaysDiff_D10']) else 0.0,
        'SameDeviceTypeDaysDiff_D11': float(df.iloc[-1]['SameDeviceTypeDaysDiff_D11']) if not pd.isna(df.iloc[-1]['SameDeviceTypeDaysDiff_D11']) else 0.0,
        'TransactionCount_C1': int(df.iloc[-1]['TransactionCount_C1']),
        'UniqueMerchants_C4': int(df.iloc[-1]['UniqueMerchants_C4']),
        'SameBRegionCount_C5': int(df.iloc[-1]['SameBRegionCount_C5']),
        'SameDeviceCount_C6': int(df.iloc[-1]['SameDeviceCount_C6']),
        'UniqueBRegion_C11': int(df.iloc[-1]['UniqueBRegion_C11']),
        'DeviceMatching_M4': int(df.iloc[-1]['DeviceMatching_M4']),
        'DeviceMismatch_M6': int(df.iloc[-1]['DeviceMismatch_M6']),
        'RegionMismatch_M8': int(df.iloc[-1]['RegionMismatch_M8']),
        'TransactionConsistency_M9': int(df.iloc[-1]['TransactionConsistency_M9'])
    }
    return result

